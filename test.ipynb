{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keybert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m BertModel, BertTokenizer\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeybert\u001b[39;00m \u001b[39mimport\u001b[39;00m KeyBERT\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m BertModel\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keybert'"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import numpy as np\n",
    "from keybert import KeyBERT\n",
    "from transformers import BertModel\n",
    "import torch\n",
    "import math\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from kobert_transformers import get_tokenizer\n",
    "import re\n",
    "from collections import Counter\n",
    "from ITglossary import ITGlossary, ITGlossaryUpdater\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "from keybert import KeyBERT\n",
    "from kiwipiepy import Kiwi\n",
    "import urllib.request\n",
    "from soyspacing.countbase import RuleDict, CountSpace\n",
    "import json\n",
    "from decimal import Decimal\n",
    "from fastapi.responses import JSONResponse\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORS 설정\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"http://localhost:3000\", \"https://ohmystack.co\"],  # 클라이언트의 도메인 주소를 여기에 추가\n",
    "    allow_methods=[\"POST\"],  # 요청 허용 메서드\n",
    "    allow_headers=[\"*\"],  # 요청 허용 헤더\n",
    ")\n",
    "\n",
    "# Load the job data\n",
    "conn = pymysql.connect(host=\"database-1.cb6dvhektjhd.ap-northeast-2.rds.amazonaws.com\", user='gihun', password='EM7E7e', db='production')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.on_event(\"startup\")\n",
    "def load_data():\n",
    "    global df\n",
    "    global glossary\n",
    "    global kw_model\n",
    "\n",
    "    query = \"SELECT * FROM production.cosine\"\n",
    "    with conn.cursor() as cursor:\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "\n",
    "    glossary = ITGlossary()\n",
    "    updater = ITGlossaryUpdater(glossary)\n",
    "    updater.update_glossary()\n",
    "    glossary.print_glossary()\n",
    "\n",
    "    model = BertModel.from_pretrained('skt/kobert-base-v1')\n",
    "    kw_model = KeyBERT(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.on_event(\"shutdown\")\n",
    "def close_connection():\n",
    "    conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define request/response models\n",
    "class JobRecommendationRequest(BaseModel):\n",
    "    self_intr: str\n",
    "\n",
    "class JobRecommendationResponse(BaseModel):\n",
    "    job_recommendations: list\n",
    "\n",
    "# Define utility functions\n",
    "def clean_text(input_text):\n",
    "    if not isinstance(input_text, str):\n",
    "        return input_text\n",
    "    input_text = input_text.lower()\n",
    "    # Remove special characters\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', input_text)\n",
    "    cleaned_text = re.sub(r'\\([^)]*\\)', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\r', '', cleaned_text)\n",
    "    # Remove newline characters\n",
    "    cleaned_text = cleaned_text.replace('\\n', '')\n",
    "    # Remove HTML tags\n",
    "    cleaned_text = re.sub(r'<[^>]+>', '', cleaned_text)\n",
    "    # Remove \"www\" or \"www~\" from the text\n",
    "    cleaned_text = re.sub(r'www~?.(\\w+.)+\\w+', '', cleaned_text)\n",
    "    # Remove \"http~\" from the text\n",
    "    cleaned_text = re.sub(r'http~?', '', cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_english(text):\n",
    "    pattern = re.compile(r'[a-zA-Z]+')\n",
    "    text_without_english = re.sub(pattern, '', text)\n",
    "    return text_without_english\n",
    "\n",
    "def translate_IT(input_text, it_glossary):\n",
    "    input_text = str(input_text)\n",
    "    words = re.findall(r'\\b[a-zA-Z]+\\b', input_text)\n",
    "    for word in words:\n",
    "        try:\n",
    "            input_text = input_text.replace(word, it_glossary[word])\n",
    "        except:\n",
    "            pass\n",
    "        input_text = input_text.replace('[', '')\n",
    "        input_text = input_text.replace(']', '')\n",
    "    return input_text\n",
    "\n",
    "def get_embedding(kw_model, keywords, self_intr):\n",
    "    tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n",
    "    embeddings = []  # 임베딩 리스트\n",
    "    weights = []  # 가중치 리스트\n",
    "    for keyword in keywords:\n",
    "        if len(keyword) > 1:  # 키워드의 길이가 1보다 큰지 확인\n",
    "            weights.append(keyword[1])  # 가중치를 리스트에서 가져옴\n",
    "            with torch.no_grad():\n",
    "                model = BertModel.from_pretrained('monologg/kobert')\n",
    "                input_ids = tokenizer.encode(keyword[0], add_special_tokens=True)\n",
    "                input_ids = torch.tensor(input_ids).unsqueeze(0)\n",
    "                last_hidden_states = model(input_ids)[0]\n",
    "                embedding = last_hidden_states[0].mean(dim=0).numpy()\n",
    "                embeddings.append(embedding)\n",
    "    if not weights or all(weight == 0 for weight in weights):\n",
    "        print(\"가중치 Null값이 발생하였습니다.\")\n",
    "        return None\n",
    "    return np.average(embeddings, axis=0, weights=weights)\n",
    "\n",
    "class NumpyJSONEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.float16, np.float32, np.float64)):\n",
    "            if np.isnan(obj) or np.isinf(obj):\n",
    "                return str(obj)\n",
    "            return float(obj)\n",
    "        if isinstance(obj, (np.int8, np.int16, np.int32, np.int64, np.uint8, np.uint16, np.uint32, np.uint64)):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, Decimal):\n",
    "            return float(obj)\n",
    "        return super().default(obj)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/job_recommendation\", response_model=JobRecommendationResponse)\n",
    "def job_recommendation(request: JobRecommendationRequest):\n",
    "    self_intr = request.self_intr\n",
    "    self_intr = translate_IT(clean_text(self_intr), glossary)\n",
    "    self_intr = remove_english(self_intr)\n",
    "    self_intr = clean_text(self_intr)\n",
    "    \n",
    "    keywords = kw_model.extract_keywords(self_intr, keyphrase_ngram_range=(1, 1), stop_words=None, top_n=10)\n",
    "    embedding = get_embedding(kw_model, keywords, self_intr)\n",
    "    embedding2 = []\n",
    "\n",
    "    for s in df[\"embedding\"]:\n",
    "        if s is None:\n",
    "            embedding2.append(np.zeros((768,), dtype=float).tolist())\n",
    "            continue\n",
    "\n",
    "        s = s.replace('\\n', '').replace('[', '').replace(']', '')\n",
    "        s = re.split(r'\\s+', s.strip())\n",
    "\n",
    "        if len(s) == 0:\n",
    "            embedding2.append(np.zeros((768,), dtype=float).tolist())\n",
    "            continue\n",
    "\n",
    "        arr = np.array(s, dtype=float)\n",
    "        arr[np.isnan(arr)] = 0  # NaN 값을 0으로 대체\n",
    "        arr[np.isinf(arr)] = 0  # Infinity 값을 0으로 대체\n",
    "        arr = arr.reshape((768,))\n",
    "\n",
    "        embedding2.append(arr.tolist())\n",
    "\n",
    "\n",
    "    cos_sim = [cosine_similarity([embedding], [emb])[0][0] for emb in embedding2]\n",
    "    cos_sim = np.array(cos_sim)\n",
    "    cos_sim[np.isnan(cos_sim)] = 0\n",
    "\n",
    "    top_indices = np.argpartition(cos_sim, -10)[-10:]\n",
    "    job_recommendations = df.iloc[top_indices].to_dict(orient='records')\n",
    "\n",
    "    response_content = json.dumps({\"job_recommendations\": job_recommendations}, cls=NumpyJSONEncoder)\n",
    "    return JSONResponse(content=response_content, media_type=\"application/json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
